{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95915f8-c166-41a9-8b76-b4f3131e1ba8",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Mask R-CNN wird mit Tipvortexcavitationdatensatz trainiert. Farbspritzereffekt(color splash effect) wird im Algorithmus Implementiert\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "# Ein neues Modell wird mit den vortrainierten Coco-Gewichten trainiert\n",
    "python3 Tipvortexcavitation.py train --dataset=/path/to/Tipvortexcavitation/dataset --weights=coco \n",
    "für Linux der Pfad und die Gewichte von Coco dataset\n",
    "python  Tipvortexcavitation.py train --dataset=C:/Users/majd4/Desktop/Bachelorarbeit/Bachelor-Arbeit-Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/datasets/Tipvortexcavitation --weights=coco\n",
    "\n",
    "# Fortsetzen des Trainierens von einem Modell, was schon trainiert wurde \n",
    "python3 Tipvortexcavitation.py train --dataset=/path/to/Tipvortexcavitation/dataset --weights=last für Linux \n",
    "python  Tipvortexcavitation.py train --dataset=D:/Bachelor-Arbeit-Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/datasets/Tipvortexcavitation --weights=last\n",
    "\n",
    "# Ein neues Modell wird mit den ImageNet-Gewichten trainiert\n",
    "python3 Tipvortexcavitation.py train --dataset=/path/to/Tipvortexcavitation/dataset --weights=imagenet für Linux\n",
    "python  Tipvortexcavitation.py train --dataset=D:/Bachelor-Arbeit-Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/datasets/Tipvortexcavitation --weights=imagenet\n",
    "    \n",
    "# Farbspritzer(color splash) auf ein Bild anwenden\n",
    "python3 Tipvortexcavitation.py splash --weights=/path/to/weights/file.h5 --image=<URL or path to file> für Linux\n",
    "python Tipvortexcavitation.py  splash --weights=D:/Bachelor-Arbeit-Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/mask_rcnn_tipvortexcavitation_0020.h5 --image=D:/Bachelor-Arbeit-Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/111.jpg\n",
    "    \n",
    "# Farbspritzer (color splash) anwenden mit den zuletzt trainierten Gewichten\n",
    "python3 Tipvortexcavitation.py splash --weights=last --video=<URL or path to file> für Linux\n",
    "python  Tipvortexcavitation.py splash --weights=last --video=<URL or path to file>  für Windows\n",
    "python Tipvortexcavitation.py splash --weights=D:/Bachelor-Arbeit-Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/mask_rcnn_tipvortexcavitation_0020.h5 --video=D:/Bachelor-Arbeit-Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/11.mp4 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858e0aed-d9cf-4b9f-bbc8-5a312eaad850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "\n",
    "# der Pfad der Datei von dem Mask R-CNN Projekt \n",
    "ROOT_DIR = os.path.abspath(\"C:/Users/majd4/Desktop/Bachelorarbeit/Bachelor-Arbeit-Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN\")\n",
    "\n",
    "# Maske RCNN importieren\n",
    "sys.path.append(ROOT_DIR)  \n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn import visualize\n",
    "\n",
    "# Pfad zur Datei mit den trainierten Gewichten\n",
    "# was vorher trainiert wurde, natürlich wird es nochmals benutzt, um ein neues Modell zu trainieren \n",
    "# es wird das neue Modell besser in der erkennung von Tipvortexcavitation\n",
    "WEIGHTSS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_tipvortexcavitation_0010.h5\")\n",
    "\n",
    "# hier ist die Datei, wo die logs gespeichert wurden \n",
    "# Epochen von dem Training \n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aed9fdf-1d47-42c6-ac1e-afba34ed0745",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TipvortexcavitationConfig(Config):\n",
    "    \"\"\"Konfiguration für das trainieren mit dem Tipvortexcavitationdatensatz\n",
    "    Abgeleitet von dem basic Config Klasse und werden einige Werte überschrieben \n",
    "    \"\"\"\n",
    "    # ANZAHL DER zu verwendenden GPUs. Wenn nur eine CPU verwendet wird, muss dies auf 1 gesetzt werden.\n",
    "    # es ist abhängig von dem Prozessor und die Grafikkarte, die man hat \n",
    "    # hier Auf meinem Laptop nutze ich AMD Ryzen 7 3700U with Radeon Vega Mobile Gfx 2.30 GHz\n",
    "    GPU_COUNT = 1\n",
    "    \n",
    "    #Die Konfiguration wird einen erkennbaren Namen gegeben \n",
    "    NAME = \"Tipvortexcavitation\"\n",
    "\n",
    "    # verwende eine GPU mit 12 GB Speicher, die zwei Bilder aufnehmen kann.\n",
    "    # Passe nach unten an, wenn eine kleinere GPU verwendet wird.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Anzahl der Klassen (einschließlich Hintergrund)\n",
    "    NUM_CLASSES = 1 + 1  # Background + Tipvortexcavitation\n",
    "    \n",
    "    # Anzahl der Farbkanäle pro Bild.  \n",
    "    # RGB = 3 (Bilder nur mit Farbe), \n",
    "    # grayscale = 1 (Bilder nur Schwarz und Weiß), \n",
    "    # RGB-D = 4 ( Bilder werden von einer Speziellen Kamera aufgenommen. \n",
    "    # jedes Pixel im Bildem ist mit einem Intensitätswert verbunden)\n",
    "    IMAGE_CHANNEL_COUNT = 3\n",
    "    \n",
    "    \n",
    "    # Backbone Netzwerk die Architektur\n",
    "    # Unterstützte Werte sind: resnet50, resnet101.\n",
    "    BACKBONE = \"resnet101\"\n",
    "\n",
    "    # Anzahl der Trainingsschritte pro Epoche\n",
    "    STEPS_PER_EPOCH = 10\n",
    "    \n",
    "    # Anzahl der Validierungsschritte, die am Ende jeder Trainingsepoche ausgeführt werden.\n",
    "    \n",
    "    VALIDATION_STEPS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37b51dfe-33ab-4db2-bd1f-3d518fbb65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TipvortexcavitationDataset(utils.Dataset):\n",
    "\n",
    "    def load_Tipvortexcavitation(self, dataset_dir, subset):\n",
    "        \"\"\"Lade eine Teilmenge des Tip Vortex Cavitation-Datensatzes.\n",
    "        \"\"\"\n",
    "        # Klassen hinzufügen.  \n",
    "        self.add_class(\"Tipvortexcavitation\", 1, \"Tipvortexcavitation\")\n",
    "\n",
    "        # Trainings- oder Validierungsdatensatz?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "       \n",
    "        annotations = json.load(open(os.path.join(dataset_dir, \"Tipvortexcavitation_json.json\")))\n",
    "        annotations = list(annotations.values())  # \n",
    "\n",
    "        \n",
    "        # Annotationen.unannotierte Bilder überspringen.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Bilder hinzufügen\n",
    "        for a in annotations:\n",
    "            # Erhalte die x, y Koordinaten der Punkte der Polygone\n",
    "            # Die Polygone werden in the shape_attributes gespeichert\n",
    "            if type(a['regions']) is dict: #annotated\n",
    "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
    "            else: # unanotated\n",
    "                polygons = [r['shape_attributes'] for r in a['regions']] \n",
    "\n",
    "            # load_mask() benötigt die Bildgröße, um Polygone in Masken zu konvertieren.\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"Tipvortexcavitation\",\n",
    "                image_id=a['filename'],  \n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Erzeuge Instanz  für ein Bild.\n",
    "       zurückgegeben:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"Tipvortexcavitation\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Erzeuge Polygone zum einem bitmap mask of shape\n",
    "        # [Höhe, Breite, Instanz_Anzahl]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            \n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        \n",
    "       \n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Gibt den Pfad des Bildes zurück.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"Tipvortexcavitation\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e617840-7095-4dd3-b644-b1338fd1d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    \"\"\" das Modell trainieren.\"\"\"\n",
    "    # Trainingsdatensatz(Trainingsdatenmenge).\n",
    "    dataset_train = TipvortexcavitationDataset()\n",
    "    dataset_train.load_Tipvortexcavitation(args.dataset, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validierungsdatensatz(Validierungsdatenmenge)\n",
    "    dataset_val = TipvortexcavitationDataset()\n",
    "    dataset_val.load_Tipvortexcavitation(args.dataset, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # keine Notwendigkeit, alle Schichten zu trainieren. \n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=10,\n",
    "                layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f73ae174-786d-4311-80fa-68998aa111fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset /path/to/balloon/dataset/]\n",
      "                             --weights /path/to/weights.h5\n",
      "                             [--logs /path/to/logs/]\n",
      "                             [--image path or URL to image]\n",
      "                             [--video path or URL to video]\n",
      "                             <command>\n",
      "ipykernel_launcher.py: error: the following arguments are required: --weights\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\majd4\\anaconda3\\envs\\Matterprot_MaskRCNN\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def color_splash(image, mask):\n",
    "    \"\"\"Farbspritzer-Effekt anwenden.\n",
    "    Bild: RGB Bild [Höhe, Breite, 3]\n",
    "    mask:Instanzsegmentierung mask [Höhe, Breite, Anzahl der Instanzen]\n",
    "\n",
    "    es wird schwarz weißes Bild mit Farbe zurückgegeben \n",
    "    \"\"\"\n",
    "    \n",
    "    # Erstelle ein schwarzweiße Kopie von dem Farbigen Bild.   \n",
    "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
    "    # Kopiere die gefärbte Maske von dem Originalbild  \n",
    "    if mask.shape[-1] > 0:\n",
    "        mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
    "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
    "    else:\n",
    "        splash = gray.astype(np.uint8)\n",
    "    return splash\n",
    "\n",
    "\n",
    "def detect_and_color_splash(model, image_path=None, video_path=None):\n",
    "    assert image_path or video_path\n",
    "\n",
    "    # Bild oder Video?\n",
    "    if image_path:\n",
    "        \n",
    "        # das Modell für erkennung ausführen und erzeuge Farbspritzereffekt(color splash effect)\n",
    "        print(\"Running on {}\".format(args.image))\n",
    "        # Bild lesen\n",
    "        image = skimage.io.imread(args.image)\n",
    "        #  Objekte erkennen\n",
    "        r = model.detect([image], verbose=1)[0]\n",
    "        # Farbspritzer\n",
    "        splash = color_splash(image, r['masks'])\n",
    "        # Ausgabe speichern \n",
    "        file_name = \"splash_{:%Y%m%dT%H%M%S}.png\".format(datetime.datetime.now())\n",
    "        skimage.io.imsave(file_name, splash)\n",
    "    elif video_path:\n",
    "        import cv2\n",
    "        \n",
    "        vcapture = cv2.VideoCapture(video_path)\n",
    "        width = int(vcapture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(vcapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = vcapture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        \n",
    "        file_name = \"splash_{:%Y%m%dT%H%M%S}.avi\".format(datetime.datetime.now())\n",
    "        vwriter = cv2.VideoWriter(file_name,\n",
    "                                  cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "                                  fps, (width, height))\n",
    "\n",
    "        count = 0\n",
    "        success = True\n",
    "        while success:\n",
    "            print(\"frame: \", count)\n",
    "            # Das nächste Bild lesen\n",
    "            success, image = vcapture.read()\n",
    "            if success:\n",
    "                # OpenCV gibt die Bilder als BGR zurück und wandelt zu RGB um \n",
    "                image = image[..., ::-1]\n",
    "                # Objekte erkennen\n",
    "                r = model.detect([image], verbose=0)[0]\n",
    "                # Farbspritzer(Farbe spritzen)\n",
    "                splash = color_splash(image, r['masks'])\n",
    "                # RGB -> BGR um ein Bild in einem Video zu speichern\n",
    "                splash = splash[..., ::-1]\n",
    "                # dem Videoschreiber ein Bild hinzufügen\n",
    "                vwriter.write(splash)\n",
    "                count += 1\n",
    "        vwriter.release()\n",
    "    print(\"Speichere zu \", file_name)\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Trainieren\n",
    "############################################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    # \n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Trainiere Mask R-CNN, um Tipvortexcavitation zu erkennen')\n",
    "    parser.add_argument(\"command\",\n",
    "                        metavar=\"<command>\",\n",
    "                        help=\"'train' or 'splash'\")\n",
    "    parser.add_argument('--dataset', required=False,\n",
    "                        metavar=\"/path/to/balloon/dataset/\",\n",
    "                        help='Directory of the Tipvortexcavitation dataset')\n",
    "    parser.add_argument('--weights', required=True,\n",
    "                        metavar=\"/path/to/weights.h5\",\n",
    "                        help=\"Path to weights .h5 file or 'coco'\")\n",
    "    parser.add_argument('--logs', required=False,\n",
    "                        default=DEFAULT_LOGS_DIR,\n",
    "                        metavar=\"/path/to/logs/\",\n",
    "                        help='Logs and checkpoints directory (default=logs/)')\n",
    "    parser.add_argument('--image', required=False,\n",
    "                        metavar=\"path or URL to image\",\n",
    "                        help='Image to apply the color splash effect on')\n",
    "    parser.add_argument('--video', required=False,\n",
    "                        metavar=\"path or URL to video\",\n",
    "                        help='Video to apply the color splash effect on')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Argumente validieren\n",
    "    if args.command == \"train\":\n",
    "        assert args.dataset, \"Argument --dataset is required for training\"\n",
    "    elif args.command == \"splash\":\n",
    "        assert args.image or args.video,\\\n",
    "               \"Provide --image or --video to apply color splash\"\n",
    "\n",
    "    print(\"Weights: \", args.weights)\n",
    "    print(\"Dataset: \", args.dataset)\n",
    "    print(\"Logs: \", args.logs)\n",
    "\n",
    "    # Konfigurationen\n",
    "    if args.command == \"train\":\n",
    "        config = TipvortexcavitationConfig()\n",
    "    else:\n",
    "        class InferenceConfig(TipvortexcavitationConfig):\n",
    "            # setz die Batchgröße(batch size) auf 1.da wir führen Inferenz auf ein Bild nach dem anderen aus \n",
    "            # Batchgröße(Batch size). Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "            GPU_COUNT = 1\n",
    "            IMAGES_PER_GPU = 1\n",
    "        config = InferenceConfig()\n",
    "    config.display()\n",
    "\n",
    "    # ein Modell erzeugen \n",
    "    if args.command == \"train\":\n",
    "        model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "    else:\n",
    "        model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "\n",
    "    # Gewichte Datei zum Laden auswählen \n",
    "    if args.weights.lower() == \"coco\":\n",
    "        weights_path = WEIGHTSS_PATH\n",
    "        # Gewichte Datei herunterladen\n",
    "        if not os.path.exists(weights_path):\n",
    "            utils.download_trained_weights(weights_path)\n",
    "    elif args.weights.lower() == \"last\":\n",
    "        # letzte trainierte Gewichte finden oder das letzte trainierte Modell mit den Gewichten finden\n",
    "        weights_path = model.find_last()\n",
    "    elif args.weights.lower() == \"imagenet\":\n",
    "        # Das neue Modell wird mit den Gewichten von Imagenetmodell Initialisieren\n",
    "        weights_path = model.get_imagenet_weights()\n",
    "    else:\n",
    "        weights_path = args.weights\n",
    "\n",
    "    # Gewichte laden\n",
    "    print(\"Gewichte laden \", weights_path)\n",
    "    if args.weights.lower() == \"coco\":\n",
    "        \n",
    "        model.load_weights(weights_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    else:\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    # Trainieren or evaluieren\n",
    "    if args.command == \"train\":\n",
    "        train(model)\n",
    "    elif args.command == \"splash\":\n",
    "        detect_and_color_splash(model, image_path=args.image,\n",
    "                                video_path=args.video)\n",
    "    else:\n",
    "        print(\"'{}' ist nicht erkannt. \"\n",
    "              \"benutze 'trainieren' oder 'splash'\".format(args.command))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f73ba-a72d-48bc-91bf-55f04d87b110",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
