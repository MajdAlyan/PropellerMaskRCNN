{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df8f758-05bf-4537-ab4d-113003bc8dbb",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Mask R-CNN wird mit Tipvortexcavitationdatensatz trainiert. Farbspritzereffekt(color splash effect) wird im Algorithmus Implementiert\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "# Ein neues Modell wird mit den vortrainierten Coco-Gewichten trainiert\n",
    "python3 Tipvortexcavitation.py train --dataset=/path/to/Tipvortexcavitation/dataset --weights=coco \n",
    "für Linux der Pfad und die Gewichte von Coco dataset.\n",
    "\n",
    "python  Tipvortexcavitation.py train --dataset=C:/Users/majd4/Desktop/Bachelorarbeit/Bachelor-Arbeit- Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/datasets/Tipvortexcavitation --weights=coco\n",
    "\n",
    "# Fortsetzen des Trainierens von einem Modell, was schon trainiert wurde \n",
    "python3 Tipvortexcavitation.py train --dataset=/path/to/Tipvortexcavitation/dataset --weights=last für Linux \n",
    "\n",
    "python  Tipvortexcavitation.py train --dataset=C:/Users/majd4/Desktop/Bachelorarbeit/Bachelor-Arbeit- Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/datasets/Tipvortexcavitation --weights=last\n",
    "\n",
    "# Ein neues Modell wird mit den ImageNet-Gewichten trainiert\n",
    "python3 Tipvortexcavitation.py train --dataset=/path/to/Tipvortexcavitation/dataset --weights=imagenet für Linux\n",
    "\n",
    "python  Tipvortexcavitation.py train --dataset=C:/Users/majd4/Desktop/Bachelorarbeit/Bachelor-Arbeit- Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/datasets/Tipvortexcavitation --weights=imagenet\n",
    "    \n",
    "# Farbspritzer(color splash) auf ein Bild anwenden\n",
    "python3 Tipvortexcavitation.py splash --weights=/path/to/weights/file.h5 --image=<URL or path to file> für Linux\n",
    "    \n",
    "python Tipvortexcavitation.py  splash --weights=C:/Users/majd4/Desktop/Bachelorarbeit/Bachelor-Arbeit- Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/mask_rcnn_tipvortexcavitation_0010.h5 --image=C:/Users/majd4/Desktop/Bachelorarbeit/Bachelor-Arbeit-Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/111.jpg\n",
    "    \n",
    "# Farbspritzer (color splash) anwenden mit den zuletzt trainierten Gewichten\n",
    "python3 Tipvortexcavitation.py splash --weights=last --video=<URL or path to file> für Linux\n",
    "    \n",
    "python  Tipvortexcavitation.py splash --weights=last --video=<URL or path to file>  für Windows\n",
    "    \n",
    "python Tipvortexcavitation.py splash --weights=C:/Users/majd4/Desktop/Bachelorarbeit/Bachelor-Arbeit- Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/mask_rcnn_tipvortexcavitation_0010.h5 --video=C:/Users/majd4/Desktop/Bachelorarbeit/Bachelor-Arbeit-Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN/11.mp4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb1c49-cfa6-432b-83bb-6c0e70c40ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "\n",
    "# der Pfad der Datei von dem Mask R-CNN Projekt \n",
    "ROOT_DIR = os.path.abspath(\"C:/Users/majd4/Desktop/Bachelorarbeit/Bachelor-Arbeit-Daten/MaskRCNNProjekt/MaskRCNN_2/Mask_RCNN\")\n",
    "\n",
    "# Maske RCNN importieren\n",
    "sys.path.append(ROOT_DIR)  \n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn import visualize\n",
    "\n",
    "# Pfad zur Datei mit den trainierten Gewichten\n",
    "# was vorher trainiert wurde, natürlich wird es nochmals benutzt, um ein neues Modell zu trainieren \n",
    "# es wird das neue Modell besser in der erkennung von Tipvortexcavitation\n",
    "WEIGHTSS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_tipvortexcavitation_0010.h5\")\n",
    "\n",
    "# hier ist die Datei, wo die logs gespeichert wurden \n",
    "# Epochen von dem Training \n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "############################################################\n",
    "#  Konfigurationen\n",
    "############################################################\n",
    "\n",
    "# Esi ist hilfreich diese Website zu lesen, wenn man Änderung auf den Code vornehmen möchte \n",
    "#  https://github.com/matterport/Mask_RCNN/wiki\n",
    "\n",
    "\n",
    "class TipvortexcavitationConfig(Config):\n",
    "    \"\"\"Konfiguration für das trainieren mit dem Tipvortexcavitationdatensatz\n",
    "    Abgeleitet von dem basic Config Klasse und werden einige Werte überschrieben \n",
    "    \"\"\"\n",
    "    # ANZAHL DER zu verwendenden GPUs. Wenn nur eine CPU verwendet wird, muss dies auf 1 gesetzt werden.\n",
    "    # es ist abhängig von dem Prozessor und die Grafikkarte, die man hat \n",
    "    # hier Auf meinem Laptop nutze ich AMD Ryzen 7 3700U with Radeon Vega Mobile Gfx 2.30 GHz\n",
    "    GPU_COUNT = 1\n",
    "    \n",
    "    #Die Konfiguration wird einen erkennbaren Namen gegeben \n",
    "    NAME = \"Tipvortexcavitation\"\n",
    "\n",
    "    # verwende eine GPU mit 12 GB Speicher, die zwei Bilder aufnehmen kann.\n",
    "    # Passe nach unten an, wenn eine kleinere GPU verwendet wird.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Anzahl der Klassen (einschließlich Hintergrund)\n",
    "    NUM_CLASSES = 1 + 1  # Background + Tipvortexcavitation\n",
    "    \n",
    "    # Anzahl der Farbkanäle pro Bild.  \n",
    "    # RGB = 3 (Bilder nur mit Farbe), \n",
    "    # grayscale = 1 (Bilder nur Schwarz und Weiß), \n",
    "    # RGB-D = 4 ( Bilder werden von einer Speziellen Kamera aufgenommen. \n",
    "    # jedes Pixel im Bildem ist mit einem Intensitätswert verbunden)\n",
    "    IMAGE_CHANNEL_COUNT = 3\n",
    "    \n",
    "    \n",
    "    # Backbone Netzwerk die Architektur\n",
    "    # Unterstützte Werte sind: resnet50, resnet101.\n",
    "    BACKBONE = \"resnet101\"\n",
    "\n",
    "    # Anzahl der Trainingsschritte pro Epoche\n",
    "    STEPS_PER_EPOCH = 10\n",
    "    \n",
    "    # Anzahl der Validierungsschritte, die am Ende jeder Trainingsepoche ausgeführt werden.\n",
    "    \n",
    "    VALIDATION_STEPS = 50\n",
    "    \n",
    "############################################################\n",
    "#  Datensatz\n",
    "############################################################\n",
    "\n",
    "class TipvortexcavitationDataset(utils.Dataset):\n",
    "\n",
    "    def load_Tipvortexcavitation(self, dataset_dir, subset):\n",
    "        \"\"\"Lade eine Teilmenge des Tip Vortex Cavitation-Datensatzes.\n",
    "        \"\"\"\n",
    "        # Klassen hinzufügen.  \n",
    "        self.add_class(\"Tipvortexcavitation\", 1, \"Tipvortexcavitation\")\n",
    "\n",
    "        # Trainings- oder Validierungsdatensatz?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "       \n",
    "        annotations = json.load(open(os.path.join(dataset_dir, \"Tipvortexcavitation_json.json\")))\n",
    "        annotations = list(annotations.values())  # \n",
    "\n",
    "        \n",
    "        # Annotationen.unannotierte Bilder überspringen.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Bilder hinzufügen\n",
    "        for a in annotations:\n",
    "            # Erhalte die x, y Koordinaten der Punkte der Polygone\n",
    "            # Die Polygone werden in the shape_attributes gespeichert\n",
    "            if type(a['regions']) is dict: #annotated\n",
    "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
    "            else: # unanotated\n",
    "                polygons = [r['shape_attributes'] for r in a['regions']] \n",
    "\n",
    "            # load_mask() benötigt die Bildgröße, um Polygone in Masken zu konvertieren.\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"Tipvortexcavitation\",\n",
    "                image_id=a['filename'],  \n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Erzeuge Instanz  für ein Bild.\n",
    "       zurückgegeben:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"Tipvortexcavitation\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Erzeuge Polygone zum einem bitmap mask of shape\n",
    "        # [Höhe, Breite, Instanz_Anzahl]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            \n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        \n",
    "       \n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Gibt den Pfad des Bildes zurück.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"Tipvortexcavitation\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n",
    "\n",
    "   \n",
    "def train(model):\n",
    "    \"\"\" das Modell trainieren.\"\"\"\n",
    "    # Trainingsdatensatz(Trainingsdatenmenge).\n",
    "    dataset_train = TipvortexcavitationDataset()\n",
    "    dataset_train.load_Tipvortexcavitation(args.dataset, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validierungsdatensatz(Validierungsdatenmenge)\n",
    "    dataset_val = TipvortexcavitationDataset()\n",
    "    dataset_val.load_Tipvortexcavitation(args.dataset, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # keine Notwendigkeit, alle Schichten zu trainieren. \n",
    "    print(\"Training network heads\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=10,\n",
    "                layers='all')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
